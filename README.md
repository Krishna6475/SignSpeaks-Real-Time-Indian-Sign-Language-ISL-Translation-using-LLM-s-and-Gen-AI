# ğŸ–ï¸ SignSpeaks: Real-Time Indian Sign Language (ISL) Translation using Generative AI & LLMs  

![SignSpeaks Banner]([https://your-image-link-here.com](https://www.livelaw.in/h-upload/2019/07/09/750x450_362025-isl.jpg))  

## ğŸ“Œ Project Overview  
SignSpeaks is an AI-powered **real-time Indian Sign Language (ISL) translation system** that converts ISL gestures into **text and speech**. It leverages **LLaMA-2 (LLM) for text processing** and **GANs for ISL image generation**, improving accessibility for the deaf and hard-of-hearing community.  

### âœ¨ Key Features  
âœ… **ISL to Text/Speech** â€“ Uses **CNN + LLaMA-2** for accurate ISL recognition and **gTTS** for speech synthesis.  
âœ… **Text to ISL Gesture Generation** â€“ Implements **cGANs & Stable Diffusion** to generate ISL images from text.  
âœ… **Real-Time Gesture Recognition** â€“ Detects **hand landmarks** using **MediaPipe Hands**.  
âœ… **End-to-End AI Pipeline** â€“ Uses **Deep Learning, Generative AI, and NLP techniques**.  

---

## ğŸ› ï¸ Technologies Used  
ğŸ”¹ **Deep Learning:** Convolutional Neural Networks (CNNs), Generative Adversarial Networks (GANs)  
ğŸ”¹ **Large Language Models (LLMs):** LLaMA-2 for text processing  
ğŸ”¹ **Computer Vision:** OpenCV, MediaPipe Hands for gesture detection  
ğŸ”¹ **NLP & Speech:** Hugging Face Transformers, gTTS for speech synthesis  
ğŸ”¹ **Frameworks:** TensorFlow, PyTorch  


## ğŸš€ Installation & Setup  
### **1ï¸âƒ£ Clone the Repository**  
```bash  
git clone https://github.com/Krishna6475/SignSpeaks-Real-Time-ISL-Translation.git  
cd SignSpeaks-Real-Time-ISL-Translation  
```

### **2ï¸âƒ£ Install Dependencies**  
```bash  
pip install -r requirements.txt  
```

---

## ğŸ“Š Dataset  
The model is trained on a curated **Indian Sign Language (ISL) dataset**, which consists of:  
- **ISL Gesture Images** (A-Z, 0-9)  
- **Hand Landmarks Extracted using MediaPipe**  
- **Annotated Text for Gesture Classification**  

---

## ğŸ“ˆ Model Architecture  
ğŸ“Œ **Phase 1: ISL to Text/Speech Translation**  
1ï¸âƒ£ **CNN + LLaMA-2** for ISL gesture classification  
2ï¸âƒ£ **BERT-based text refinement** for structured sentence formation  
3ï¸âƒ£ **gTTS for speech output**  

ğŸ“Œ **Phase 2: Text to ISL Gesture Generation**  
1ï¸âƒ£ **Conditional GANs (cWGAN-GP)** for ISL image generation  
2ï¸âƒ£ **Stable Diffusion for high-quality gesture synthesis**  

---

## ğŸ¤ Contribution Guidelines  
Contributions are welcome! Follow these steps to contribute:  
1. **Fork the repository**  
2. **Create a new branch** (`git checkout -b feature-branch`)  
3. **Commit your changes** (`git commit -m "Add new feature"`)  
4. **Push to GitHub** (`git push origin feature-branch`)  
5. **Create a Pull Request**  

---

## ğŸ“œ License  
This project is licensed under the **MIT License** â€“ see the [LICENSE](LICENSE) file for details.  

---

## ğŸ“© Contact & Acknowledgments  
ğŸ‘¤ **Chinthagunta Vamshi Krishna**  
âœ‰ï¸ Email: [my_mail](mailto:vamshikrishna6475@gmail.com)  
ğŸ”— LinkedIn: [my LinkedIn Profile](https://www.linkedin.com/in/vamshi-krishna-chinthagunta-73321625b/)  

ğŸ’¡ **Acknowledgments:**  
- Inspired by **research in AI-driven ISL translation**.  
- Special thanks to **academic mentor** for guidance.  

---

ğŸš€ *SignSpeaks is an ongoing research project and is currently in the process of being published. Due to publication constraints, not all models and implementation details have been included in this repository. Feel free to reach out for further discussions.*  
